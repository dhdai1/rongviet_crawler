{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import os\n",
    "\n",
    "def setup_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--start-maximized\")\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    return BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "def extract_links(soup):\n",
    "    parent_body = soup.find('ul', class_='flex flex-1 flex-col gap-y-0.5')\n",
    "    list_li = parent_body.find_all('li')\n",
    "    links = [li.find('a').get('href') for li in list_li]\n",
    "    return links\n",
    "\n",
    "def fetch_page_content(url):\n",
    "    response = requests.get(url)\n",
    "    return BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "def extract_text_and_images(driver, url):\n",
    "    driver.get(url)\n",
    "    div_main_element = driver.find_element(By.XPATH, \"/html/body/div/div/div/div/main/div[1]\")\n",
    "    all_text = \"\"\n",
    "    try:\n",
    "        child_elements = div_main_element.find_elements(By.XPATH, \"./*\")\n",
    "    except:\n",
    "        return all_text\n",
    "\n",
    "    for child in child_elements:\n",
    "        try:\n",
    "            all_text += child.text + \"\\n\"\n",
    "            img_elements = child.find_elements(By.TAG_NAME, \"img\")\n",
    "            if img_elements:\n",
    "                for img in img_elements:\n",
    "                    img_src = img.get_attribute(\"src\")\n",
    "                    all_text += f\"URL: {img_src}\" + \"\\n\"\n",
    "            if child.tag_name == \"details\":\n",
    "                child.click()\n",
    "                time.sleep(1)\n",
    "                p_elements = child.find_elements(By.TAG_NAME, \"p\")\n",
    "                if p_elements:\n",
    "                    answer = ''.join([p.text + \"\\n\" for p in p_elements])\n",
    "                    all_text += \"Câu trả lời: \" + answer + \"\\n\\n\"\n",
    "        except Exception:\n",
    "            continue\n",
    "    return all_text\n",
    "\n",
    "def save_to_file(folder_name, endpoint, content):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    file_name = f\"{endpoint.split('/')[-1]}.txt\"\n",
    "    with open(f\"{folder_name}/{file_name}\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(content)\n",
    "\n",
    "def main():\n",
    "    driver = setup_driver()\n",
    "    list_domain = [\n",
    "        'https://smart-dragon.gitbook.io/',\n",
    "        'https://vietdragon.gitbook.io/'\n",
    "\n",
    "    ]\n",
    "    for domain in list_domain:\n",
    "        folder_name = domain.split('//')[1].split('.')[0]\n",
    "        soup = get_soup(domain)\n",
    "        links = extract_links(soup)\n",
    "        \n",
    "        for endpoint in links:\n",
    "            url = f\"{domain}{endpoint}\"\n",
    "            page_soup = fetch_page_content(url)\n",
    "            main_result = page_soup.find('main')\n",
    "            all_text = main_result.find('header').find('h1').text + \"\\n\"\n",
    "            try:\n",
    "                sub_header = main_result.find('header').find('p').text\n",
    "                all_text += sub_header + \"\\n\"\n",
    "            except:\n",
    "                pass\n",
    "            all_text += extract_text_and_images(driver, url)\n",
    "            save_to_file(folder_name, endpoint, all_text)\n",
    "        \n",
    "    driver.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
